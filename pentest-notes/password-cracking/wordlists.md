# Wordlists

[https://github.com/berzerk0/Probable-Wordlists](https://github.com/berzerk0/Probable-Wordlists)

[https://github.com/danielmiessler/SecLists](https://github.com/danielmiessler/SecLists)

siph0n.net

### Reduce your wordlist for WPA2 Cracking

`cat wpa.txt | awk 'length >=8 && length <=20' | uniq > new-wordlist.txt`

`time cat Words.txt | uniq | awk 'length >=8 && length <=20' > wua`

[https://www.youtube.com/watch?v=uYJsyg0vgPo&feature=youtu.be](https://www.youtube.com/watch?v=uYJsyg0vgPo&feature=youtu.be)

### Crunch

`man crunch` for a very complete help and explanation

_**crunch &lt;min&gt; max&lt;max&gt;&lt;characterset&gt; -t &lt;pattern&gt; -o &lt;output filename&gt;**_

```text
crunch 6 8 123abc -o wordlist -t a@@@@b -f /path/to/charset.lst <charactersetname>
```

```text
crunch 8 8 -f /usr/share/rainbowcrack/charset.txt mixalpha-numeric -o /root/mywordlist.lst
```

## Mentalist

[https://github.com/sc0tfree/mentalist](https://github.com/sc0tfree/mentalist)

Mentalist is a graphical tool for custom wordlist generation. It utilizes common human paradigms for constructing passwords and can output the full wordlist as well as rules compatible with [Hashcat](https://hashcat.net/hashcat) and [John the Ripper](http://www.openwall.com/john)

### Rsmangler

[https://digi.ninja/projects/rsmangler.php](https://digi.ninja/projects/rsmangler.php)

### CeWL

[https://digi.ninja/projects/cewl.php](https://digi.ninja/projects/cewl.php)

Scrape a target website and generate a wordlists baseed on the words found. `cewl -m 8 http://www.google.com.` _**An idea**_ is the use Rsmangler afterwards to enhance the wordlist

### See also section [03 - Editing text](../../introduction/chapter1/linux/02-editing-text.md)

## Grep

grep for a string in a big file in the whole directory

[https://stackoverflow.com/questions/13913014/grepping-a-huge-file-80gb-any-way-to-speed-it-up](https://stackoverflow.com/questions/13913014/grepping-a-huge-file-80gb-any-way-to-speed-it-up)

LC\_ALL=C fgrep -r "ernesto.laban" \* or LANG=C fgrep -r "ernesto.laban" \*

[https://stackoverflow.com/questions/9066609/fastest-possible-grep](https://stackoverflow.com/questions/9066609/fastest-possible-grep)

#### Parallels

[https://www.gnu.org/software/parallel/man.html\#NAME](https://www.gnu.org/software/parallel/man.html#NAME)

To process a big file or some output you can use **--pipe** to split up the data into blocks and pipe the blocks into the processing program.

`cat bigfile.txt | parallel --pipe grep 'pattern'`

`< mybigfile parallel --pipe grep 'string-to-search'`

`cat BIGFILE | parallel--pipe grep -f PATTERNFILE`

## Useful one-liners for wordlist manipulation

**Remove duplicates**

```text
awk '!(count[$0]++)' old.txt > new.txt
```

Type the following command to get rid of all duplicate lines:

```text
sort garbage.txt | uniq –u
```

**Sort by length**

```text
awk '{print length, $0}' old.txt | sort -n | cut -d " " -f2- > new.txt
```

**Sort by alphabetical order**

```text
sort old.txt | uniq > new.txt
```

**Merge multiple text files into one**

```text
cat file1.txt file2.txt > combined.txt
```

```text
cat file1.txt file2.txt | sort | uniq > output.txt
```

**Remove all blank lines**

```text
egrep -v "^[[:space:]]*$" old.txt >  new.txt
```

**Append file**

```text
cat file2 >> file1
```

**Remove duplicates**

Assuming that the words are one per line, and the file is already sorted:

```text
uniq filename
```

If the file's not sorted:

```text
sort filename | uniq
cat filename.txt | sort | uniq > newfile.txt
```

"sort -u" would remove the need for uniq

**I want to remove last character from a line:**

```text
sed 's/.$//'
```

The syntax is s\(ubstitute\)/search/replacestring/. The . indicates any character, and the $ the end of the line. So .$ will remove the last character only.

**Remove words shorter than 8**

You could use`sed`. The following would remove lines that are 7 characters long or smaller:

```text
sed –ir.bak '/^.{,7}$/d' filename
```

In order to save the changes to the file in-place, supply the`-i`option.

If your version of`sed`doesn't support extended RE syntax, then you could write the same in BRE:

```text
sed '/^.\{,3\}$/d' filename
```

Using`sed`, removing lines of length **5** or less:

```text
sed -r '/^.{,5}$/d' file.txt
```

Reverse way, printing lines of length six or more:

```text
sed -nr '/^.{6,}$/p' file.txt
```

You can save the output in a different file using`>`operator like`grep`or edit the file in-place using`-i`option of`sed`:

```text
sed -ri.bak '/^.{6,}$/' file.txt
```

The original file will be backed up as`file.txt.bak`and the modified file will be`file.txt`. If you do not want to keep a backup:

```text
sed -ri '/^.{6,}$/' file.txt
```

It's very simple:

```text
grep ...... inputfile >  resultfile #There are 6 dots
```

This is extremely efficient, as`grep`will not try to parse more than it needs, nor to interpret the chars in any way: it simply send a \(whole\) line to stdout \(which the shell then redirects to resultfile\)\_as soon as\_it saw 6 chars on that line \(`.`in a regexp context matches any 1 character\).

So grep will only output lines having 6 \(or more\) chars, and the other ones are not outputted by grep so they don't make it to resultfile. You could also use`awk`:

```text
awk 'length($0)>7' filename
```

**Split big files** M = Mb

```text
split -b 1G -d bigfile bigfile-part
```

